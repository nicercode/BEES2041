---
title: "Week 3-1 linear models"
output: html_output
#   moodlequiz::moodlequiz:
#     replicates: 1
#   html_document:
#     toc: true
# moodlequiz:
#  category: "Week 3-1 linear models"
editor_options:
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

# remotes::install_github("numbats/moodlequiz")
library(moodlequiz)

# For the prac
library(tidyverse)
library(palmerpengiuns)

# Data for prac
data_towers <- read.csv("week 3/Wk3-1-moodle/data/towers-2024.csv")

# webr counter
reditor_count <- 1

class_id <- function() {
  reditor_count <<- reditor_count + 1
  sprintf("r-editor-%d", reditor_count)
}
```

<!-- Examples

- present 2 +examples of linear regression
- for each, link the question being asked to statistcal method.
- run the linear regression for each examples, relate the output to question being asked
  - check can access various parts of output

-->

# Introduction to linear models

Linear models are one of the most powerful and widely used tools in statistics and data science. At their core, they help us understand relationships between variables. 

In this prac, weâ€™ll explore how to fit and interpret, using real data. By the end, you'll have a solid foundation for applying these models in your own work. 

### Key learning objectives

We've got quite to get through today, our learning objective today are:

- **run** a **linear regression** in R using `lm()`
- **interpret** the output of a **linear regression** using:
  - `summary()`
  - `parameters()`
    - **extract** the **confidence interval** for the **slope** and **intercept** of the **regression** line
  - `report()`
  - `estimate_means()`
- **plot** the data and the **regression** line
  - add the **confidence interval** using output of `estimate_means()`

Letâ€™s dive in! ðŸš€ 

![Artwork by @allison_horst](you-can-do-it.png){width=80%}
<br>

### Setting up

**Materials:**

Everything you need for this practical is on Moodle

1.  Download the `Wk3-1-materials.zip` zip file from Moodle, from the course page
2.  Extract the zip file into your `BEES2041/` folder
3.  Unzip the file by:
    - **MacOS:** Double clicking the zip file
    - **Windows:** Right click on the zip file and click **"Extract All"**
4.  Go into the folder `Wk3-1-materials` created by extracting the zip.
5.  Click on the `Wk-3-1-linear-models.Rproj` to open the RStudio project and you're in!!!

We will be working with real-world datasets collected by researched in the School of Biological, Earth & Environmental Sciences. These are in the folder `data/`.

**Setting up: Packages:**

We will also be working with packages from the `tidyverse` and `easystats`, building on skills from previous pracs. You should have these already installed on your machines.

**Note** that when running R in the browser we need to install the packages each time we start a new session or after you've checked your answer

In case you don't have them installed, here is code for you to do so:
```{r, eval=FALSE}
# Uncomment and run only the lines below only if you have not previously installed these.
# install.packages("tidyverse")
# install.packages("easystats")
# install.packages("palmerpenguins")
```

> Remember to load the packages into R to use em! 

```{r, results='hide', warning=FALSE, message=FALSE}
library(tidyverse)
library(easystats)
library(palmerpengiuns)
```

# A Refresher: Population means and sampling 

In the previous prac, we learned about population means and the process of sampling. Here is a quick visualisation to illustrate the key message: 

> When we take a sample, our sample mean will always be taken with some error

```{r}
# Set the true mean and sd for the population
true_mean <- 5
true_sd <- 2

# Create a tibble with the population and sample means
# Take a sample of 1000 observations from a population with mean 5 and standard deviation 2
data1 <- tibble(
  value = rnorm(1000, mean = true_mean, sd = true_sd),
  type = "Population of 1000"
)

# take 1000 samples of 10 observations from a population with mean 5 and standard deviation 2
data2 <- tibble(
  value = replicate(1000, mean(rnorm(10, mean = true_mean, sd = true_sd))),
  type = "Sample mean"
)

# combine the population and sample means
data <- bind_rows(data1, data2)

# plot the distribution of the population and sample means
data |>
  ggplot(aes(x = value, fill = type)) +
  geom_histogram(binwidth = 0.5, color = "black", alpha = 0.5) +
  facet_wrap(~type) +
  labs(title = "Distribution of population and sample means", x = "Value", y = "Frequency")
```

This is the nature of sampling and for this reason, we estimate **confidence intervals** to capture the uncertainty in our samples. Let's move on 

# Isaac with leaves across climates

![](isaac-plant-ecosystems.png){60%}
From lectures, Data Dan walked us through an example of a linear model from a study conducted by Dr. Isaac Towers, a postdoc in the School of Biological, Earth & Environmental Sciences. Isaac was interested in understanding the relationship between leaf-construction (`log10_leaf_mass_per_area`) and rainfall (`log10_rainfall`). His research is published in New Phytologist, you can have a read of his original study [here](https://nph.onlinelibrary.wiley.com/doi/10.1111/nph.19478) We will be working with the data Isaac compiled for us. 

Let's read in the Isaac's data. This is in your `"data/"` folder. 

```{r, eval=FALSE}
data_towers <- read.csv("data/towers-2024.csv")
```

To fit a linear model, we will be using the `lm()` function like so:

**Note**: Remember to assign the output of `lm()` into an object so R can save it for you in your environment

```{r}
towers_fit <- lm(log10_leaf_mass_per_area ~ log10_rainfall, data = data_towers)
```

Recall from lectures the slope (aka gradient) of a linear model describes how our y variable (`log10_leaf_mass_per_area`) changes with x (`log10_rainfall`)

![](slope-explainer.png)

Let's inspect the results of your model use `summary(towers_fit)` and see how this corresponds to the image above

```{r}
summary(towers_fit)
```

**Question:**

1. Which coefficient corresponds to the slope in the output of `summary(towers_fit)`? 

The slope is `r cloze("log10_rainfall", c("(Intercept)", "log10_rainfall"))` and the coefficient value is `r cloze("-0.543846", c("3.805973", "-0.543846", "<2e-16"))`

2. What direction is slope coefficient, what does this tell us?

The slope is 


parameters(fit)

report(fit)

means <- estimate_means(fit, by = "log10_rainfall")

p_results <-
  ggplot(data_towers, aes(x = log10_rainfall, y = log10_leaf_mass_per_area)) +
  geom_point(size = 2, col = "red", alpha = 0.2, stroke = 0) +
  geom_ribbon(data = means, aes(ymin = CI_low, ymax = CI_high, y = Mean), fill = "grey") +
  geom_line(data = means, aes(y = Mean), col = "#eb8240", size = 1) +
  theme_classic() +
  labs(
    title = "Response of woody-plants to rainfall",
    x = "log10 Rainfall",
    y = "log10 Leaf Mass per Area"
  ) 

p_results
```

# Bringing the Palmer penguins back for allometry



# Lisa and Lizard size


# Air Quality
```{r}
data(airquality)
model <- lm(Ozone ~ Temp, data = airquality, na.action = na.omit) # Exclude missing data
summary(model)
ggplot(airquality, aes(x = Temp, y = Ozone)) +
  geom_point() +  # Scatter plot
  geom_smooth(method = "lm", se = FALSE, color = "blue") +  # Add linear regression line
  labs(title = "Ozone vs Temperature with Linear Regression Line",
       x = "Temperature (F)",
       y = "Ozone Level (ppb)") +
  theme_minimal()
```

# Introduction to ANOVA

In this week's lectures, we learned that linear regression are incredibly flexible. Not only can we use them to make inferences about the relationship of continuous variables, we can also use them to test for **differences in means** between **discrete** or **categorical** variables. 

Recall the differences between  **discrete** or **categorical** variables. 

![A colourful example of  **continuous** and **discrete/categorical** variables](continuous-discrete.png){70%}

```{r}
library(tidyverse)
library(easystats)
library(palmerpenguins)
```

# Mean differences in Palmer Penguins

```{r}
penguins|> select(x = island, y = Sepal.Width)

fit <- lm(y ~ x, data = data_iris_anova_3grp)

summary(fit)

parameters(fit)

means <- estimate_means(fit, by = "x")

anova(fit)
report(fit)

estimate_contrasts(fit, contrast = "x")

# Plot with raw data points
  ggplot(means, aes(x = x, y = Mean)) +
  geom_jitter(data = data_iris_anova_3grp, aes(x = x, y = y), color = "red", width = 0.1) + # Raw data
  geom_errorbar(aes(ymin = CI_low, ymax = CI_high), width = 0, color = "grey", size = 3) + # Confidence intervals
  geom_point(size = 5, color = "orange") + # Estimated means
  theme_classic() + # Style plot
  labs(y = "y")
```


# Insecticides and crops

```{r}
# Load the dataset
InsectSprays

# Fit a linear model treating spray as a categorical predictor
model <- lm(count ~ spray, data = InsectSprays)

# Perform ANOVA
anova_result <- anova(model)

# Print results
print(anova_result)

# Check model summary
summary(model)
```