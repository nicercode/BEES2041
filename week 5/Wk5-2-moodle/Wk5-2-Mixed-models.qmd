---
title: "Mixed models"
format:
  html:    
    self-contained: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)

# Set the working directory
rprojroot::has_file("BEES2041-code.Rproj") |>
  rprojroot::find_root() |>
  file.path("week 5/Wk5-2-moodle/") |>
  setwd()

# remotes::install_github("numbats/moodlequiz")
library(moodlequiz)

# For prac
library(tidyverse)
library(easystats)
library(glmmTMB)

data_urchins <- read_csv("data/Urchins.csv")  |> 
  mutate(
    logBareRock = log(BareRock + 1),
    Quadrat = as.factor(Quadrat),
  )
```

<!-- # Outline -->
<!-- - Fixed and Random effects -->
<!-- - How to construct a model forumula -->
<!--   - varying intercepts -->
<!--   - varying slopes -->
<!-- - How to choose to suit question -->


# Introduction to Mixed Models

![Bringing all your R skills together!](images/witches.png){width=60%}

## Introduction

Hey folks! In many real-world datasets, our observations are not entirely independent â€” measurements might be grouped by subjects, locations, time points, or experimental units. Ignoring this structure can lead to biased estimates and misleading results. **Mixed models** (also known as linear mixed-effects models) help us handle this complexity by explicitly modeling both fixed effects â€” the overall trends we're interested in â€” and random effects â€” the variation due to these groupings.

Today, we will go through  XXXX: 

> 


## Key learning objectives

Our learning objectives today are:

- **understand** how different predictor variable types can influence your choice of analysis 
- **understand** difference between additive and interactive effects
- **run** a multiple linear regression in R using `lm()`
- **test** for effects of your predictor variables using `anova()`
- **interpret** the output of your multiple regression using `parameters()`, `estimate_means()`, `estimate_contrasts()`
- **extract** the mean and confidence interval for the slope and intercept of the regression line
- **plot** the data and the regression line with confidence intervals

Letâ€™s dive in! ðŸš€ 

## Setting up: Materials

Everything you need for this prac is on Moodle

1. Download this week's materials zip file from Moodle, from the course page
2. Unzip the file by: 
  - MacOS: Double clicking the zipfile 
  - Windows: Right click on the zip file and click "Extract All" 
3. Move the extracted folder into the folder where you store materials for `BEES2041/` 
4. **Click on the Rstudio project file, eg. `Wk5-2-mixed-models.Rproj`** to open the RStudio project and you're in!!!

We will be working with various datasets collected. These are in the folder `data/`.

You will work in the relevant Quarto document for this prac. Within each Quarto docs there are several challenges for you to complete on your own devices in order to **answer the questions on Moodle**.

## Setting up: Packages

> **Note** that when running R in the browser we need to install the packages each time we start a new session or after you've checked your answers. We're only going to install the parts of `tidyverse` and `easystats` we need for this prac.

```{r, eval=FALSE}
# install.packages("tidyverse")
# install.packages("easystats")
# install.packages("patchwork")
# install.packages("glmmTMB")
```

> Remember to load the packages into R to use em!

```{r, results='hide', warning=FALSE, message=FALSE}
library(tidyverse)
library(easystats)
library(patchwork)
library(glmmTMB)
```

# Random Intercept

You will need to use mixed effect models if you have a random factor in your experimental design. A **random factor** is: 

- categorical
- has a large number of levels but,
- only a random subsample of levels is included in your design and, 
- you want to make inference in general and not only for the levels you observed.

## Worked Example: Estuaries

![](images/estuaries.jpg){width=60%} <br>

Random factors are hard to get your head around, and is best explained with an example. The data we will analyse here are **counts of invertebrates at 3-4 sites pristine and modified sites in each of 7 (randomly chosen) estuaries**.

**Our research question is: How does total inverebrate counts differ between pristine and modified sites across all estuaries?**

Here the estuaries are the **random effect**, as there are **a large number of possible estuaries**, and we only sampled a few from the wider population of them, but we would like to make inference about estuaries in general.

Let's read in the dataset first

```{r}
data_estuaries <- read_csv("data/Estuaries.csv")

data_estuaries
```

A handy way to understand the structure of your study design is to create a table of counts. Here we are tabulating `Modification` by `Estuary` so we have a breakdown of how many samples we have in each category. 

```{r}
data_estuaries |> 
  count(Modification, Estuary)
```

> Notice that `Estuary` is not replicated across both levels of `Modification`. This is because, `Estuary` is not our primary variable of interest. We collected data we needed randomly from these estuaries. 

Importantly, we know that our sample of estuaries are likely to harbour different abundances of invertebrates. For example, some estuaries may be more productive, or climate may be more favourable to invertebrates than others. Ultimately, we know that different estuaries is likely to differ, on average in `Total` number of invertebrates. This random effect of `Estuary` is something we want to account for in our model. 

## Fit our mixed model

Let's fit the model together and we will talk through the code. For mixed models, we will be using the `glmmTMB` package and function. The way we write a model is very similar to what we have been doing in `lm()` and `glm()`.

```{r}
fit_estuaries <- glmmTMB(Total ~ Modification + (1 | Estuary), data = data_estuaries, REML = T)
```

- `Total` is our numeric, continuous response variable (y) 
- `Modification` is our categorial predictor variable (x)
- `(1 | Estuary)` is a **random intercept**. This tells the model that we are fitting 

> Technically `Total` count data, but it's distribution doesn't really resemble a Poisson distribution. A Normal distribution fits it quite well! Create a histogram and see for yourself! 

We can proceed with checking out model fit before looking at the model's output. Things are looking okay!

```{r}
# Check our model
check_model(fit_estuaries) 
```

## Compute estimated means

By now, you are familar with `estimate_means()` and `estimate_contrasts()`. For mixed models, we need to use a different function `estimate_expectations()` to compute means for each level of our predictors and random effect. 

```{r}
means_by_mod_estuaries <- estimate_expectation(fit_estuaries)  

head(means_by_mod_estuaries)
```

There are a lot of repeated rows here! This is because `estimate_expectations()` generates mean predictions for the same number of rows and replicates we had in the data. You can verify this by counting the number of rows for `Modification` and `Estuary` and the values should match with our earlier table of counts.

```{r}
means_by_mod_estuaries |> 
  count(Modification, Estuary)
```

> Let's use these means and CI to visualise our data

## Visualise our data

Here we are plotting our raw data across different estuaries and facetting the plot by our variable of interest `Modification`.

```{r}
ggplot(data_estuaries, aes(x = Estuary, y = Total, colour = Modification)) +
  geom_errorbar(data = means_by_mod_estuaries, 
                aes(x = Estuary, y = Predicted, ymin = CI_low, ymax = CI_high),
                width = 0.15,
                col = "azure4") +
  geom_violin(fill = NA) +
  geom_jitter(width = 0.3, alpha = 0.5) + 
  geom_point(data = means_by_mod_estuaries, aes(y = Predicted), colour = "azure4", size = 2) + 
  scale_color_manual(values = c("burlywood4", "cadetblue")) + 
  theme_classic() + 
  facet_grid(~Modification, scales = "free") + 
  # facet_wrap(~Modification) +
  theme(legend.position = "none")
```

There are three things that might be new to you in this code:

- `scale_color_manual(values = c("burlywood4", "cadetblue"))` allows me to see the colours manually for my plot
- `facet_grid(~Modification, scales = "free")` is very similar to `facet_wrap()` but the only difference it allows the x and y axes to differ in values. This is useful here because we didn't sample at the same estuaries for both `Modified` and `Pristine` sites. You can replace `facet_grid()` with `facet_wrap()` and see for yourself! 
- `theme(legend.position = "none")` hides the legend. The legend here is redundant to the facet title so I decided to ditch it. 

> So let's go ahead and test whether `Modification` has an effect on `Total` invertebrate abundance.

## Test for an effect of `Modification`

Since this is a simple model with 1 predictor, we can use the `parameters()` output but if you prefer, you can also use `estimate_contrasts()` to see whether we have a signficant difference between `Modified` and `Pristine` sites

<!-- TODO: Walk through # Random effects of paramaters? -->

```{r}
parameters(fit_estuaries)
estimate_contrasts(fit_estuaries)
```

**Questions:**

**1. What does the Intercept represent in the paramters output?** 

The `Intercept` represents the `r cloze("mean", c("mean","min","max"))` `Total` number of invertebrates from the `r cloze("Modified", c("Modified","Pristine"))` site.

**2. Intepret the `Modification [Pristine]` cofficient and p-value**

The `Modification [Pristine]` coefficient is `r cloze("-14.47", c("-14.47", "40.97", "7.42"))`. This value represents the mean difference in `Total` number of invertebrates between `Modified` and `Pristine` sites. The value is `r cloze("negative", c("negative", "positive"))` which means the mean in `Total` is `r cloze("lower", c("higher", "lower"))` for `Pristine` sites.

## Exercise Example: Urchins

![**Urchin grazing**](images/Urchins.jpg){width=60%}

In the last prac, we worked with this sea urchin dataset. This data was collected marine researchers in BEES who were studying sea urchins at Bare Island near the opening of Botany Bay ([Wright et al. 2005](http://www.int-res.com/abstracts/meps/v298/p143-156/)). Urchins are voracious grazers and at high densities can remove entire kelp forests and leave bare areas known as urchin barrens. 

To study how urchins affect the communities on the rocky reef, researchers set up five experimental treatments on the sea floor:

- cages that enclosed a high density of urchins
- cages that enclosed a low density of urchins
- cages with no urchins (cage control)
- cages with no urchins and no top (open cage)
- control plots with no manipulation.

**These researchers wanted to know: "How do urchin densities affect algal cover over time?"**

The **% cover of `BareRock`** were measured several times over **210 days**, using **quadrats** (Like you did in the Maroubra field trip!)

We fitted a linear model containing **one categorical and one continuous predictor**, this is also know as an **ANCOVA**: 

- `Day` was treated as a covariate. We are not really interested in `Day` as an effect but we know that time is a factor and would likely affect the % of `BareRock`.
- The main effect of `Treatment`. 
- The interaction between Day and Treatment `Day:Treatment`

```{r}
fit_urchins <- lm(logBareRock ~ Day + Treatment + Day:Treatment, data = data_urchins)
```

From this model, we produced this plot: 

<details>
    <summary>Plot code here:</summary>
```{r}
means <- estimate_means(fit_urchins, by = c("Day", "Treatment"))

p1 <-
  ggplot(means, aes(x = Day, y = Mean, color = Treatment)) +
#  geom_ribbon(aes(ymin = CI_low, ymax = CI_high, fill = Treatment), alpha = 0.2) +
  geom_line() +
  labs(
    x = "Day",
    y = "log(BareRock)"
  ) +
  theme_minimal()

# Compare lines with data
p1 +
  geom_point(data = data_urchins, aes(y = logBareRock)) +
  facet_wrap(~Treatment)
```

</details>

```{r, echo=FALSE}
p1 +
  geom_point(data = data_urchins, aes(y = logBareRock)) +
  facet_wrap(~Treatment)
```


> **But we forgot an important sampling design detail!**

The researchers collected data using `Quadrats`, this is the sampling unit. They sampled 360 quadrats. While we're not particularly interested in the `Quadrats` themselves, we know that each time we use them, the % `BareRock` will differ by chance. We also know our 360 `Quadrats` are really a sample from a much wider population of `Quadrats` and we want be able to make inferences about any `Quadrat` in general. 

> Your task is to refit the same model, adding `Quadrat` as a random intercept and reproduce the results again ðŸš€!

Let's get you hitting the ground running: 

Here is the code to: 
- read in the `data/urchins.csv` dataset. 
- log transform the y vaiable (`BareRock`) as it is a percentage and will be right skewed. 
- setting the `Quadrat` variable as a factor/catergorical variable as it is recorded as integers.

```{r}
# Read in data 
data_urchins <- read_csv("data/Urchins.csv")  |> 
  mutate(
    logBareRock = log(BareRock + 1),
    Quadrat = as.factor(Quadrat),
  )
```


```{r}
fit_urchins_random <- glmmTMB(logBareRock ~ Day + Treatment + Day:Treatment +  (1 | Quadrat), data = data_urchins)

check_model(fit_urchins_random)

parameters(fit_urchins_random)

anova(fit_urchins_random) # doesn't work

# estimate_contrasts(fit_urchins, contrast = "Treatment", by = "Day") |>
#   filter(Day == 0)
# 
# estimate_contrasts(fit_urchins, contrast = "Treatment", by = "Day") |>
#   filter(Day == 210)   

means <- estimate_expectation(fit_urchins_random, by = c("Day", "Treatment"))
means2 <- estimate_expectation(fit_urchins_random)

p1 <-
  ggplot(means2, aes(x = Day, y = Predicted, color = Treatment)) +
  geom_line(aes(group = Quadrat), alpha = 0.5, size = 0.5) +
  labs(
    x = "Day",
    y = "log(BareRock)"
  ) +
  theme_minimal() +
  geom_line(data = means, alpha = 1, linewidth = 2)

p1

# Plot for each treatmeant
p1 +
  geom_point(data = data_urchins, aes(y = logBareRock)) +
  facet_wrap(~Treatment)

# Plot for each Quadrat
p1 +
  geom_point(data = data_urchins, aes(y = logBareRock)) +
  facet_wrap(~Quadrat)

parameters(fit_urchins)
parameters(fit_urchins_random)

## Ignoring qudrat adds to noise
## CI's are smaller with the random effect included
```

**Questions:**

*1.*

*2.*

*3.*


# Random Slopes

## BAAD

**Questions:**

*1.*

*2.*

*3.*

# Random Interpepts and Slopes

## BAAD

**Questions:**

*1.*

*2.*

*3.*
