---
title: "Multiple predictors"
format:
  html:    
    self-contained: true
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

# Set the working directory
rprojroot::has_file("BEES2041-code.Rproj") |>
  rprojroot::find_root() |>
  file.path("week 5/Wk5-1-moodle") |>
  setwd()

# remotes::install_github("numbats/moodlequiz")
library(moodlequiz)

# For prac
library(tidyverse)
library(easystats)
library(palmerpenguins)

```

# Outline

- two categoircal predictors (2 way anova)
  - Qu: do both factors have an effect, how big is the effect, is it interactive or additive
  - Example 1: Penguins: size by sex and species
  - Example 2: Environmental computing: Invert richness by substrate and copper treatment

- Two continuous predictors
  - addtive effect
  - Angela height: altitude and rainfall

- Two continuous predictors with interaction
  - Does efecct of X on Y change with Z?
  - Isaac leaves

- One categorical, one continuous variable
  - Question concerns sloep, looking for difference between groups
  - Example 1: Urchins

## Key learning objectives
# Introduction to Linear Regression with Multiple predictors

## Introduction

Welcome back! So far in our linear models, we have been working with linear or generalised linear models with a **single predictor** (i.e x variable) to explain variation in the response variable. While **single predictors** are straightforward to understand for simple experimental designs, we often need **more than one predictor** to help us capture real-world complexity to answer our research questions. 

First let's briefly recap on variable types, as this will determine the choice of analyses you will do: 

- **continuous variable** is a numerical variable that can take any value within a range, including decimals. e.g `bill_length_mm`

- **categorical variable** is a variable (AKA discrete variable) that represents distinct groups e.g. `islands` `species`

![](images/continuous-discrete.png){width=60%}

Today, we will go through three different use cases that have different combinations of predictor variables: 

1. Two **categorical** predictors 
    - main additive effects
    - interactive effects 
2. Two **continuous** predictors
    - main additive effects
    - interactive effects 
3. One **categorical** predictor, one continuous predictor

> Note in all use cases today, our response variable (y) is continuous.

## Key learning objectives

Our learning objectives today are:

- **understand** how different predictor variable types can influence your choice of analysis 
- **understand** difference between additive and interactive effects
- **run** a multiple linear regression in R using `lm()`
- **test** for effects of your predictor variables using `anova()`
- **interpret** the output of your multiple regression using `parameters()`, `estimate_means()`, `estimate_contrasts()`
- **extract** the mean and confidence interval for the slope and intercept of the regression line
- **plot** the data and the regression line with confidence intervals

Letâ€™s dive in! ðŸš€ 

## Setting up: Materials

Everything you need for this prac is on Moodle

1. Download this week's materials zip file from Moodle, from the course page
2. Unzip the file by: 
  - MacOS: Double clicking the zipfile 
  - Windows: Right click on the zip file and click "Extract All" 
3. Move the extracted folder into the folder where you store materials for `BEES2041/` 
4. **Click on the Rstudio project file, eg. `Wk5-1-multi-regression.Rproj`** to open the RStudio project and you're in!!!

We will be working with various datasets collected. These are in the folder `data/`.

You will work in the relevant Quarto document for this prac. Within each Quarto docs there are several challenges for you to complete on your own devices in order to **answer the questions on Moodle**.

## Setting up: Packages

> **Note** that when running R in the browser we need to install the packages each time we start a new session or after you've checked your answers. We're only going to install the parts of `tidyverse` and `easystats` we need for this prac.

```{r, eval=FALSE}
install.packages("dplyr")
install.packages("palmerpenguins")
install.packages("readr")
install.packages("ggplot2")
install.packages("performance")
install.packages("modelbased")
install.packages("see")
install.packages("emmeans")
install.packages("patchwork")
```

> Remember to load the packages into R to use em!

```{r, results='hide', warning=FALSE, message=FALSE}
library(dplyr)
library(palmerpenguins)
library(readr)
library(ggplot2)
library(performance)
library(modelbased)
library(patchwork)
```

# Use case 1: Two **categorical** predictors (Two-way ANOVA)

Some research designs are interested in the effects of **two categorical variables** on the continuous response variable. In these instances, we use **Two-way ANOVA** (Analysis of Variance) - a statistical method that help us to examine:

- **Main effects** â€“ The **independent impact** of each categorical variable on the outcome.

- **Interaction effect** â€“ Whether the **effect of one variable depends on the level of the other**.

> Recall that ANOVA at their core, are linear models. 

This means that we can fit a **two-way ANOVA** using the `lm()` function

Using `anova()` on the model fit object, we can **test whether the overall main effect and interaction effect the predictors are important** or not.

We can also look at the output of using `parameters()` to see **HOW big the main/interactive effect** is. 

## Worked Example: Penguins: Body mass by sex and species

![](images/palmer_penguins.png){width=60%}

We are all familiar with the Palmer Penguins by now, let's get to know them better with multiple regression. 

**Our research question: How much does body mass vary by sex and penguin species?**

Our **continuous response** variable (y) is: `body_mass_mm`
Our **two categorical predictor** variables (x1, x2) are: `sex` and `species`



First, let's exclude the penguins where `sex` is NA. These are juvenille penguins that won't contribute to answering our question.

```{r}
penguins_adults <- penguins |>
  filter(!is.na(sex)) # Exclude sex when its NA

summary(penguins_adults)
```

Now with our data all prepped, we can fit our linear model for our **two-way ANOVA**


```{r}
fit2 <- lm(body_mass_g ~ sex + species + sex:species , data = penguins_adults)



parameters(fit2)
parameters(fit1)

anova(fit2)
anova(fit1)


```


```{r}



fit1 <- lm(body_mass_g ~ species * sex, data = penguins_adults)

anova(fit)

ggplot(data2, aes(x = species, y = body_mass_g, fill = sex, col = sex)) +
  geom_violin() +
  #  geom_jitter() +
  labs(
    x = "Species",
    y = "Bill depth (mm)"
  )

means <- estimate_means(fit, by = c("sex", "species"))

estimate_contrasts(fit, contrast = c("sex"), by = c("species"))
estimate_contrasts(fit, contrast = c("species"))

ggplot(data2, aes(x = species, y = body_mass_g, colour = sex, group = sex)) +
  geom_jitter() +
  geom_line(data = means, aes(y = Mean)) +
  geom_ribbon(data = means, aes(y = Mean, ymin = CI_low, ymax = CI_high), alpha = 0.2) +
  theme_minimal() +
  labs(
    title = "Body Mass by Species and Sex",
    y = "bill_depth_mm",
    x = "Body Mass (g)",
    fill = "Sex"
  ) 
```

## Exercise Example: Marine Invertebrates Richness 
 
 <!-- - Example 2: Environmental computing: Invert richness by substrate and copper treatment -->
 
```{r}

```


# Use case 2: Two **continuous** predictors 
## Worked example - Isaac leaves (main effects)

```{r}
data_leaves <- read_csv("data/towers-2024.csv")
```

Additive model

```{r}
fit <- lm(log10_leaf_mass_per_area ~ log10_rainfall + temperature, data = data_leaves)

parameters(fit)
```

## Worked example - Isaac leaves (interactive effects)

```{r}
fit <- lm(log10_leaf_mass_per_area ~ log10_rainfall * temperature, data = data_leaves)

parameters(fit)
anova(fit)

means <- estimate_prediction(fit)

means1 <- estimate_means(fit, by = c("log10_rainfall")) |>
  mutate(temperature = 16)

means2 <- estimate_means(fit, by = c("log10_rainfall", "temperature"))

# plot
ggplot(means2, aes(x = log10_rainfall, y = Mean, group = temperature, color = temperature)) +
  geom_point(data = data_leaves, aes(y = log10_leaf_mass_per_area), alpha = 0.5, col = "red") +
  geom_line() +
  geom_line(data = means1, col = "orange") +
  labs(
    x = "log10_rainfall",
    y = "log10_leaf_mass_per_area"
  )
```


# Use case 3: One categorical, one continuous variable (ANCOVA) 
## Worked Example: Urchins

```{r}

# read in data: 
data_urchins <- read_csv("data/Urchins.csv") %>%
  mutate(
    Quadrat = as.factor(Quadrat)
  )
```

```{r}
fit <- lm(BareRock ~ Day*Treatment, data = urch)

check_model(fit)

# neeeds a log transofrm
data_urchins <- data_urchins %>% mutate(logBareRock = log(BareRock + 1))

fit_log <- lm(logBareRock ~ Day * Treatment, data = data_urchins)

check_model(fit_log)

parameters(fit_log)

anova(fit_log)
```

```{r}
means <- estimate_means(fit_log, by = c("Day", "Treatment"))

p1 <-
  ggplot(means, aes(x = Day, y = Mean, color = Treatment)) +
  geom_line() +
  labs(
    x = "Day",
    y = "log(BareRock)"
  ) +
  theme_minimal()

# Compare lines
p1

# Compare lines with data
p1 +
  geom_point(data = data_urchins, aes(y = logBareRock)) +
  facet_wrap(~Treatment)
```

Add a random effect for Quadrat

```{r}
library(glmmTMB)


fit <- glmmTMB(logBareRock ~ Day + Treatment + Day:Treatment +  (1 | Quadrat), data = data_urchins)

fit_simple <- glmmTMB(logBareRock ~ Day * Treatment, data = data_urchins)

check_model(fit)

means <- estimate_expectation(fit, by = c("Day", "Treatment"))
means2 <- estimate_expectation(fit)

p1 <-
  ggplot(means2, aes(x = Day, y = Predicted, color = Treatment)) +
  geom_line(aes(group = Quadrat), alpha = 0.5, size = 0.5) +
  labs(
    x = "Day",
    y = "log(BareRock)"
  ) +
  theme_minimal() +
  geom_line(data = means, alpha = 1, size = 2)

p1

# Plot for each treatmeant
p1 +
  geom_point(data = data_urchins, aes(y = logBareRock)) +
  facet_wrap(~Treatment)

# Plot for each Quadrat
p1 +
  geom_point(data = data_urchins, aes(y = logBareRock)) +
  facet_wrap(~Quadrat)

parameters(fit_simple)
parameters(fit)

## Ignoring qudrat adds to noise
## CI's are smaller with the random effect included
```


## Exercise Example: Penguins again

Want to test for differences in bill depth between species, use bill length as a covariate, because larger penguins have larger bills overall

```{r}
library(palmerpenguins)
data_penguins <- penguins

fit <- lm(bill_depth_mm ~ bill_length_mm * species, data = data_penguins)

means <- estimate_expectation(fit, by = c("bill_length_mm", "species"))

parameters(fit)
ggplot(data_penguins, aes(x = bill_length_mm, y = bill_depth_mm, color = species)) +
  geom_point() +
  geom_line(data = means, aes(y = Predicted)) +
  labs(
    x = "Bill length (mm)",
    y = "Bill depth (mm)"
  )

anova(fit)

estimate_contrasts(fit)

# Simple analysis without covariate

fit_simple <- lm(bill_depth_mm ~ species, data = data_penguins)

parameters(fit_simple)
estimate_contrasts(fit_simple)
```

