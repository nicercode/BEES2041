---
title: "Multiple predictors"
format:
  html:    
    self-contained: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

# Set the working directory
rprojroot::has_file("BEES2041-code.Rproj") |>
  rprojroot::find_root() |>
  file.path("week 5/Wk5-1-moodle") |>
  setwd()

# remotes::install_github("numbats/moodlequiz")
library(moodlequiz)

# For prac
library(tidyverse)
library(easystats)
library(palmerpenguins)

```

<!-- # Outline -->

<!-- - two categoircal predictors (2 way anova) -->
<!--   - Qu: do both factors have an effect, how big is the effect, is it interactive or additive -->
<!--   - Example 1: Penguins: size by sex and species -->
<!--   - Example 2: Environmental computing: Invert richness by substrate and copper treatment -->

<!-- - Two continuous predictors -->
<!--   - addtive effect -->
<!--   - Angela height: altitude and rainfall -->

<!-- - Two continuous predictors with interaction -->
<!--   - Does efecct of X on Y change with Z? -->
<!--   - Isaac leaves -->

<!-- - One categorical, one continuous variable -->
<!--   - Question concerns sloep, looking for difference between groups -->
<!--   - Example 1: Urchins -->

# Introduction to Linear Regression with Multiple predictors

## Introduction

Welcome back! So far in our linear models, we have been working with linear or generalised linear models with a **single predictor** (i.e x variable) to explain variation in the response variable. While **single predictors** are straightforward to understand for simple experimental designs, we often need **more than one predictor** to help us capture real-world complexity to answer our research questions. 

First let's briefly recap on variable types, as this will determine the choice of analyses you will do: 

- **continuous variable** is a numerical variable that can take any value within a range, including decimals. e.g `bill_length_mm`

- **categorical variable** is a variable (AKA discrete variable) that represents distinct groups e.g. `islands` `species`

![](images/continuous-discrete.png){width=60%}

Today, we will go through three different use cases that have different combinations of predictor variables: 

1. Two **categorical** predictors 
    - main additive effects
    - interactive effects 
2. Two **continuous** predictors
    - main additive effects
    - interactive effects 
3. One **categorical** predictor, one continuous predictor

> Note in all use cases today, our response variable (y) is continuous. But you could apply the same principles to binary or count data in a Generalised Linear Model (GLM).

## Key learning objectives

Our learning objectives today are:

- **understand** how different predictor variable types can influence your choice of analysis 
- **understand** difference between additive and interactive effects
- **run** a multiple linear regression in R using `lm()`
- **test** for effects of your predictor variables using `anova()`
- **interpret** the output of your multiple regression using `parameters()`, `estimate_means()`, `estimate_contrasts()`
- **extract** the mean and confidence interval for the slope and intercept of the regression line
- **plot** the data and the regression line with confidence intervals

Letâ€™s dive in! ðŸš€ 

## Setting up: Materials

Everything you need for this prac is on Moodle

1. Download this week's materials zip file from Moodle, from the course page
2. Unzip the file by: 
  - MacOS: Double clicking the zipfile 
  - Windows: Right click on the zip file and click "Extract All" 
3. Move the extracted folder into the folder where you store materials for `BEES2041/` 
4. **Click on the Rstudio project file, eg. `Wk5-1-multi-regression.Rproj`** to open the RStudio project and you're in!!!

We will be working with various datasets collected. These are in the folder `data/`.

You will work in the relevant Quarto document for this prac. Within each Quarto docs there are several challenges for you to complete on your own devices in order to **answer the questions on Moodle**.

## Setting up: Packages

> **Note** that when running R in the browser we need to install the packages each time we start a new session or after you've checked your answers. We're only going to install the parts of `tidyverse` and `easystats` we need for this prac.

```{r, eval=FALSE}
install.packages("dplyr")
install.packages("palmerpenguins")
install.packages("readr")
install.packages("ggplot2")
install.packages("performance")
install.packages("modelbased")
install.packages("see")
install.packages("emmeans")
install.packages("patchwork")
```

> Remember to load the packages into R to use em!

```{r, results='hide', warning=FALSE, message=FALSE}
library(dplyr)
library(palmerpenguins)
library(readr)
library(ggplot2)
library(performance)
library(modelbased)
library(patchwork)
```

# Two way ANOVA

## Use case 1: Two **categorical** predictors (Two-way ANOVA)

Some research designs are interested in the effects of **two categorical variables** on the continuous response variable. In these instances, we use **Two-way ANOVA** (Analysis of Variance) - a statistical method that help us to examine:

- **Main effects** â€“ The **independent impact** of each categorical variable on the outcome.

- **Interaction effect** â€“ Whether the **effect of one variable depends on the level of the other**.

> Recall that ANOVA at their core, are linear models. 

This means that we can fit a **two-way ANOVA** using the `lm()` function

Using `anova()` on the model fit object, we can **test whether the overall main effect and interaction effect the predictors are important** or not.

We can also look at the output of using `parameters()` to see **HOW big the main/interactive effect** is. 

## Worked Example: Penguins: Body mass by sex and species

![](images/palmer_penguins.png){width=60%}

We are all familiar with the Palmer Penguins by now, let's get to know them better with two way Anova. 

**Our research question: How much does body mass vary by sex and penguin species?**

The **continuous response** variable (y) is: `body_mass_mm`
The **two categorical predictor** variables (x1, x2) are: `sex` and `species`

First, let's exclude the penguins where `sex` is NA. These are juvenille penguins that won't contribute to answering our question.

```{r}
data_penguins_adults <- penguins |>
  filter(!is.na(sex)) # Exclude sex when its NA

summary(data_penguins_adults)
```

Now with our data all prepped, we can fit our linear model for our **two-way ANOVA**. 
Based on **our research question: How much does body mass vary by sex and penguin species?**, we want determine the **main effects** of sex and species as well as their **interactive effects**. 

This is how we fit our two-way ANOVA:

```{r}
fit_penguin_adults <- lm(body_mass_g ~ sex + species + sex:species, data = data_penguins_adults)
```

> Let's talk through the predictors, including: 

- `sex` as a standalone predictor means we are interested in the sole effect of sex on body mass
- `species` as a standalone predictor means we are interested in the sole effect of species on body mass
- `sex:species` means we are interested in the **interactive effects** of both sex and species. In other words, the effect on body mass may depend sex AND species. 

## ANOVA output

Ok, let's look at the output of `anova(fit_penguin_adults)` to see whether the main/interactive effects were important in explaining variation in body mass.

What can we see? 

```{r}
anova(fit_penguin_adults) 
```

We can see our predictor variables listed as rows. **Each row tests whether an effect signficantly affects body mass**. 

- The first rows for  the main effect of `sex`
- The second row for the main effect of ` species` after main effect of `sex`
- The third row for the interactive effect of `sex` and `species` after the two main effects.

This output tells us that both the **main effects** of sex and species and their **interactive effects** have a strong effect on body mass variation in Palmer penguins. 

**Questions:**

**1. Looking at the values for Sum Sq/Mean Sq, can you deduce which main effect explains has a stronger effect on body mass?**

The Sum Sq/Mean Sq values for `sex` are smaller/larger than the Sum Sq/Mean Sq values for `species`. This means that sex/species has a stronger/weaker effect on body mass

**2. Looking at the F value and P value for the main and interactive effects. Which one has a stronger effect on body mass?**

The F value/P value values for both the main effects (`sex` and `species`) are smaller/larger than the F value/P value values for the interaction `sex:species`. This means that interactive effects of sex and species has a weaker/stronger effect on body mass.

> But how big is the effect of sex, species and their interactive effects on body mass?

## Model output

We will need to look at the output of our multiple linear regression using `paramaters(fit_penguin_adults)`

This table looks fuller compared to the ones we've seen right? We've got more rows here.

Recall in a linear model where there are categorical predictors, the `Intercept` represents the **mean of your response variable for a reference groups**

In our penguins study here, the **reference group are the female Adelie** penguins. **The coefficient is 3368.84 is the mean body mass for female Adelie penguins**.

R chooses the reference groups level by alphabetical order for each main effect. 

```{r}
parameters(fit_penguin_adults)
```

Knowing this important fact about the `Intercept`, we can start to interpret the other rows in this model output. Recall that in a linear model containing categorical predictors, each row represents the **difference relative to the reference group due to that specific predictor**. 

For example:

- `sex [male]` represents the **difference in mean body mass between the Intercept (female Adelie) and male Adelie penguins (674.66)**. This means that the Intercept (3368.84) + 674.66 is the mean mass for male Adelie penguins. 

- `species [Chinstrap]` is the **difference in mean body mass between the Intercept (female Adelie) and female Chinstrap penguins (158.37)**. 

- `sex [male] Ã— species [Chinstrap]` is the **difference in mean body mass between the Intercept (female Adelie) and male Chinstrap penguins (-262.89)**. This value is negative, implying the male Chinstraps are smaller than the Intercept (female Adelie).

**Questions:**

**1. What does `sex [male] Ã— species [Gentoo]` represent?**

The coefficient for `sex [male] Ã— species [Gentoo]` is 130.44/-262.89/1310.91. This represents the difference in/p-value for mean body mass between female Adelie/Chinstrap/Gentoo penguins and male Gentoo/Adelie/Chinstrap penguins.

**2. Interpret the p-value for `species [Gentoo]`**

The p-value for `species [Gentoo]` is < .001/0.014/0.089. This indicates that the probability for finding the difference of 1310.91/3368.84/674.66 in mean body mass between female/male Gentoo penguins and female/male Adelie pengions is very low/high.

The output of `parameters(fit_penguin_adults)` gives us a snapshot of the how big of the effect of sex and species for a reference group but this is not particularly useful. 

## Contrasts

To answer our research question, what we _really_ want to know is: 

1.  The **difference of body mass** for all possible combinations/*constrasts* of sex and species `estimate_contrasts()`

We've specificied `contrast = c("sex", "species")` so the function will calculate the difference in body mass for all combinations for groups.

We are arranging our contrasts by `Level2` so there is a bit more structure to the output. You can also arrange by `Difference` to see which combinations showed the biggest difference

```{r}
constrasts_penguin_adults <- estimate_contrasts(fit_penguin_adults, contrast = c("sex", "species"))

constrasts_penguin_adults |>
  arrange(Level2, Difference)
```

See how the difference for  `male, Adelie | female, Adelie` row is 674.66. This is the same value from the `sex [male]` row in the model output above. 

**Questions:**

1. Which species and sex combination showed the largest difference in body mass? 

The largest difference was between male/female Adelie penguins and male/female Gentoo/Chinstrap/Adelie penguins. The absolute difference in body mass was  2116.00/740.77/411.76.

What's useful is that you can estimate constrasts for a main effect while holding the other effects constant. 

Here we are calculating the difference between the sexes and taking an average over species

```{r}
estimate_contrasts(fit_penguin_adults, contrast = c("sex"))
```

Here we are calculating the difference between the species taking an average over sexes

```{r}
estimate_contrasts(fit_penguin_adults, contrast = c("species"))
```

## Mean of the response

To answer our research question, we want to obtain:

2. The **mean body mass** for all possible combinations of sex and species `estimate_means()` 

```{r}
means_penguin_adults <- estimate_means(fit_penguin_adults, by=c("sex", "species"))

means_penguin_adults
```

**Questions:**

1.  What does the 95% CI represent for `female | Gentoo` penguins? 

The 95% CI internal for `female | Gentoo` penguins represents the range of values where we would find the true population estimate of body mass for female/male Gentoo/Chinstrap/Adelie penguins 95% of the time.

## Reporting results

**Our research question was how much does body mass vary by sex and penguin species?**

Let's report on our findings. 

There was a **significant main effect of sex** on body mass, F(1, 327) = 406.15, p < .001, indicating that males and females penguins differ in body mass.

<!-- Ignore this header as it is an essay question -->
## Report on the main effect of `species` {type=essay}
**Report on the main effect of `species`** 

_ANOVA_

We found a  **significant interaction effect between sex and species**, F(2, 327) = 8.76, p < .001, indicating that the difference in body mass between males and females penguins depends on the species.

Overall, our multiple linear regression model explained R^2 = 28%/64%/85% of variation in body mass. 

_Contrasts_

Generally female/male pengiuns are smaller than male penguins (mean difference = 630.51, 95% CI = 560.27 - 700.75, p-value = <0.001). 

<!-- Ignore this header as it is an essay question -->
## Report on the constrasts of `species` {type=essay}
**Report on the constrasts of `species`** 

There were no statistical differences in body mass male Chinstrap and male Adelie penguins (Chinstrap-Adelie = -104.52g, 95% CI = -230.90 - 21.85, p-value =  0.105). There were marginal differences in body mass between female Chinstrap and female Adelie penguins (Chinstrap-Adelie = 158.37, 95% CI = 31.99 - 284.7, p-value = 0.014). All other pairwise combinations were highly significant. See Figure 1 below. 

```{r}
ggplot(data_penguins_adults, aes(x = sex, y = body_mass_g, fill = sex, col = sex)) +
  geom_violin(alpha = 0.3) +
  geom_jitter(width = 0.1) +
  geom_errorbar(data = means_penguin_adults, aes(y = Mean, ymin = CI_low, ymax = CI_high),col = "black", width = 0.2) + 
  geom_point(data = means_penguin_adults, aes(y = Mean), col = "black") + 
  labs(
    x = "Sex",
    y = "Body Mass (g)"
  ) + 
  theme_classic() + 
  facet_wrap(~species)  +
  theme(legend.position = "none") 
```

> Notice we are calling `means_penguin_adults` in `geom_errorbar()` and `geom_point()` as we want to plot the mean body mass and their associated CIs. 

# Over to you: Two way ANOVA

## Exercise Example: Marine Invertebrates Richness 
 
 <!-- - Example 2: Environmental computing: Invert richness by substrate and copper treatment -->
 
```{r}

```


# Two continuous predictors 

## Use case 2: Two **continuous** predictors

Let's move on to our next use case: **two continuous predictors**. Recall from week 3, Isaac was interested in how leaf construction changed with climate. Previously, we found that leaf mass per area decreased as rainfall increased.

Additonally, Isaac asked **whether temperature had an effect on leaf mass per area**? He first wanted to test the **main effects** of rainfall and temperature on leaf mass per area.

Let's load the data and fit a linear model to test the main effects of both rainfall and temperature on log10 leaf mass per area.
```{r}
data_leaves <- read_csv("data/towers-2024.csv")
```

Fit a model with rainfall and temperature as predictors
```{r}
fit <- lm(log10_leaf_mass_per_area ~ log10_rainfall + temperature, data = data_leaves)
```

Now check out the parameters of the model

```{r}
parameters(fit)
```

What can we see?

- The *Intercept* is the mean `log10_leaf_mass_per_area` when both rainfall and temperature are 0.
- The `log10_rainfall` coefficient is the change in `log10_leaf_mass_per_area` for a one unit increase in log10 rainfall, holding temperature constant. As we found previously, **this effect is signifcant**, with rainfall having a negative effect on `log10_leaf_mass_per_area` by _0.54 units per unit of `log10_rainfall`.
- The `temperature` coefficient is the change in `log10_leaf_mass_per_area` for a one unit increase in temperature, holding rainfall constant. 


Questions:

- What is the estimated effect (slope) of `log10_rainfall` on `log10_leaf_mass_per_area`? `r cloze("-0.54", c("-0.42", "close to zero", "3.81"))`
- What is the estimated effect (slope) of `temperature` on `log10_leaf_mass_per_area`? `r cloze("close to zero", c("-0.42", "close to zero", "3.81"))`
- Is the effect of `log10_rainfall` significantly different to zero? `r cloze("yes", c("yes", "no"))`
- Is the effect of `temperature` significantly different to zero? `r cloze("no", c("yes", "no"))`

## Interactive effects

Now, Isaac was interested in **whether the effect of rainfall on leaf mass per area depended on temperature**. In other words, he wants to know if the slope of the relationship between rainfall and leaf mass per area changes with temperature. This is an **interactive effect**.

Let's fit a model with an interaction term between `log10_rainfall` and `temperature`:

```{r}
# fit the model
fit <- lm(log10_leaf_mass_per_area ~ log10_rainfall + temperature + log10_rainfall:temperature, data = data_leaves)

# parameters
parameters(fit)
```

Interesting! Now all the effects are significant. There's an effect of `log10_rainfall`, and an interaction with temperature. 

| So let's plot the relationship between `log10_rainfall` and `log10_leaf_mass_per_area` for different temperatures.

## Plotting the interactive effect

As we've done previously, we can use `estimate_means()` to get the means of y with respect to x1 and x2. Specificailly, we can estimate the mean `log10_leaf_mass_per_area` for

- different levels of `log10_rainfall` and `temperature`, and 
- different levels of `log10_rainfall` only, averaging out the effect of temperature.

```{r}
# estimate the means
means <- estimate_means(fit, by = c("log10_rainfall", "temperature"))

# estimate the overall means for rainfall only
means_overall <- estimate_means(fit, by = c("log10_rainfall"))

# plot
ggplot(data_leaves, aes(x = log10_rainfall, y = log10_leaf_mass_per_area)) +
  geom_point(alpha = 0.5, col = "red") + # the data`
  geom_line(data = means, aes(y = Mean, group = temperature, color = temperature)) + # means by temperature
  geom_line(data = means_overall, aes(y = Mean), col = "orange") + # overall mean
  labs(
    x = "log10_rainfall",
    y = "log10_leaf_mass_per_area"
  ) +
  theme_classic()
```


## Overall effect of rainfall in second model?

Say we'd run the model with the interaction term, but we wanted to know the overall effect of `log10_rainfall` on `log10_leaf_mass_per_area`, averaged over the different temperatures. We can use `estimate_slopes` to get this estimate. This corresponds to the slope of the orange line in the plot above.

```{r}
estimate_slopes(fit, trend = "log10_rainfall")
```
You can see the effect estimated here is very close to that we calculated above in the addtive model. This makes sense.


**Questions**

1. Why might Isaac be interested in the interactive effect of rainfall and temperature on leaf mass per area? `r cloze("to better understand the effect", c("to better understand the nature of the effect", "to see if the effect of rainfall is significant", "to see if the effect of rainfall is negative"))`

2. What is the estimated effect of `log10_rainfall` on `log10_leaf_mass_per_area` when averaged over temperature? `r cloze("-0.52", c("-0.26", "-0.52", "2.94"))`

3. Based on these results, what can we say about the effect of `log10_rainfall` on `log10_leaf_mass_per_area`? `r cloze("It has limited direct effect, but changes the effect of rainfall on leaves", c("It is negative", "It is positive", "It is close to zero", "It has limited direct effect, but changes the effect of rainfall on leaves"))`

# Use case 3: One categorical, one continuous variable (ANCOVA) 
## Worked Example: Urchins

```{r}

# read in data: 
data_urchins <- read_csv("data/Urchins.csv") %>%
  mutate(
    Quadrat = as.factor(Quadrat)
  )
```

```{r}
fit <- lm(BareRock ~ Day*Treatment, data = data_urchins)

check_model(fit)

# neeeds a log transofrm
data_urchins <- data_urchins %>% mutate(logBareRock = log(BareRock + 1))

fit_log <- lm(logBareRock ~ Day * Treatment, data = data_urchins)

check_model(fit_log)

parameters(fit_log)

anova(fit_log)
```

```{r}
means <- estimate_means(fit_log, by = c("Day", "Treatment"))

p1 <-
  ggplot(means, aes(x = Day, y = Mean, color = Treatment)) +
  geom_line() +
  labs(
    x = "Day",
    y = "log(BareRock)"
  ) +
  theme_minimal()

# Compare lines
p1

# Compare lines with data
p1 +
  geom_point(data = data_urchins, aes(y = logBareRock)) +
  facet_wrap(~Treatment)
```

Add a random effect for Quadrat

```{r}
library(glmmTMB)


fit <- glmmTMB(logBareRock ~ Day + Treatment + Day:Treatment +  (1 | Quadrat), data = data_urchins)

fit_simple <- glmmTMB(logBareRock ~ Day * Treatment, data = data_urchins)

check_model(fit)

means <- estimate_expectation(fit, by = c("Day", "Treatment"))
means2 <- estimate_expectation(fit)

p1 <-
  ggplot(means2, aes(x = Day, y = Predicted, color = Treatment)) +
  geom_line(aes(group = Quadrat), alpha = 0.5, size = 0.5) +
  labs(
    x = "Day",
    y = "log(BareRock)"
  ) +
  theme_minimal() +
  geom_line(data = means, alpha = 1, size = 2)

p1

# Plot for each treatmeant
p1 +
  geom_point(data = data_urchins, aes(y = logBareRock)) +
  facet_wrap(~Treatment)

# Plot for each Quadrat
p1 +
  geom_point(data = data_urchins, aes(y = logBareRock)) +
  facet_wrap(~Quadrat)

parameters(fit_simple)
parameters(fit)

## Ignoring qudrat adds to noise
## CI's are smaller with the random effect included
```

# Over to you: 

## Exercise Example: Penguins again

Want to test for differences in bill depth between species, use bill length as a covariate, because larger penguins have larger bills overall

```{r}
library(palmerpenguins)
data_penguins <- penguins

fit <- lm(bill_depth_mm ~ bill_length_mm * species, data = data_penguins)

means <- estimate_expectation(fit, by = c("bill_length_mm", "species"))

parameters(fit)
ggplot(data_penguins, aes(x = bill_length_mm, y = bill_depth_mm, color = species)) +
  geom_point() +
  geom_line(data = means, aes(y = Predicted)) +
  labs(
    x = "Bill length (mm)",
    y = "Bill depth (mm)"
  )

anova(fit)

estimate_contrasts(fit)

# Simple analysis without covariate

fit_simple <- lm(bill_depth_mm ~ species, data = data_penguins)

parameters(fit_simple)
estimate_contrasts(fit_simple)
```

