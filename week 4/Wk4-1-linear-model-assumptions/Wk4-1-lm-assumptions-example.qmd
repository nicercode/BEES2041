---
title: "Week 4-1 Linear model assumptions"
output: html_document
editor_options:
  chunk_output_type: console
---

# Checking linear model asusmptions

## Introduction

In the previous practical, we learned about using linear models to understand how `y` varies with a continuous `x` variable and a discrete `x` variable ...but how do we know our models are any good? Can we evaluate the validity of our linears models? 

In this practical, we will 

- build on what we learned last week, fitting linear modeles.
- explore approaches to assess how well our model fits the data, and ways on how to improve our model fits using transformation. 
- practice interpretation the outputs of models. 

Throughout we will work with various real-world datasets. By the end of today, youâ€™ll have a solid foundation for applying these techniques to models you will be fitting in your own work.

## Key learning objectives

Our learning objective today are:

- **run** a **linear regression** in R using `lm()`
- **interpret** the output of a **linear regression** 
- **run diagnostic checks** on your  model output using `check_model()` to assess whether it meets the assumptions of a linear model.

Letâ€™s dive in! ðŸš€ 

![Image credit:  @allison_horst](images/r-learners.png){width=80%} <br>

## Setting up

**Materials:**

Everything you need for this prac is on Moodle

1. Download this week's materials zip file from Moodle, from the course page
2. Unzip the file by: 
  - MacOS: Double clicking the zipfile 
  - Windows: Right click on the zip file and click "Extract All" 
3. Move the extracted folder into the folder where you store materials for `BEES2041/` 
4. **Click on the Rstudio project file, eg. `Wk4-1-lm-assumptions.Rproj`** to open the RStudio project and you're in!!!

We will be working with various datasets collected. These are in the folder `data/`.

You will work in the relevant Quarto document for this prac. Within each Quarto docs there are several challenges for you to complete on your own devices in order to **answer the questions on Moodle**.

**Setting up: Packages:**

We will also be working with packages from the `tidyverse` and `easystats`, building on skills from previous pracs. You should have these already installed on your machines. The packages listed below are part of the `tidyverse` and `easystats` suite of packages.

In case you don't have them installed, here is code for you to do so:
```{r, eval=FALSE}
# Uncomment and run only the lines below only if you have not previously installed these.
# install.packages("tidyverse")
# install.packages("easystats")
```

> Remember to load the packages into R to use em!

```{r, results='hide', warning=FALSE, message=FALSE}
library(tidyverse)
library(easystats)
```

## Worked example - Isaac with leaves across climates

![Remember Dr. Isaac Towers?! Image credit: Data Dan](images/isaac-plant-ecosystems.png){width=60%} <br>
We will be working with an example from Dr. Isaac Towers - a postdoc in the School of Biological, Earth & Environmental Sciences. Specifically, Isaac wants to know: How does a leaf's mass per area change with rainfall? His research is published in New Phytologist, you can have a read of his original study [here](https://nph.onlinelibrary.wiley.com/doi/10.1111/nph.19478). We will be working with the data Isaac compiled for us.  Recall, last week we ran a linear model using `log10_leaf_mass_per_area`, `log10_rainfall`, let's try run the same linear model again but with the raw, untransformed data.

## Read in data from a URL link

```{r}
# The link the contains our data
url <- "https://raw.githubusercontent.com/nicercode/BEES2041/refs/heads/main/week%203/Wk3-1-Linear-models/data/towers-2024.csv"

# Read in the data, drop columns where their names start with `log10`
data_towers <- read_csv(url) |>
  select(-starts_with("log10"))

data_towers
```

## Fit model

```{r}
towers_og_fit <- lm(leaf_mass_per_area ~ rainfall, data = data_towers)

summary(towers_og_fit)
```

## Check model assumptions

Recall from lectures this week that the assumptions of a linear model assumes:

1. **Linear** relationship between `x` and `y` 
2. **Residuals** are **normally** distributed
3. **Constant variance** of residuals (homogeneity of variance)
4. No major **outliers** / influential observations
5. **Independence** of points (sampling design)
6. Our **samples represent the population** of interest? (sampling design)

The last two assumptions has to do with the sampling design. You can only check the validity of these by carefully considering the how data was collection. Let's assume that Isaac has done a good job in collecting his data and that the last two assumptions are met.

We can check the remaining assumptions (1-4) using the the outputs of `check_model()`.

> Note, you may need to click on "Zoom" to give the plots some room to breathe

```{r}
check_model(towers_og_fit)
```

In [this week's lectures](https://youtu.be/zzFyjTnAa8Y?si=LpkRecpF0LSVu91N), Data Data goes through how to use the four main plots neccessary for checking the assumptions of a liner model: 

1. **Linearity**
    - Check the relationship between fitted values and residuals
        - Should see no structure or patterns/curvature

2. **Normality of Residual**
    - Check the Quantile-Quantile plot
        - Sample points should fall along the line

3. **Homogeneity of Variance**
    - Check the relationship between fitted values and square root of standardised residuals
        - Line should be flat and horizontal
        - No clear pattern in points e.g. fanning out or grouping

4. **Influential Observations**
    - Check the leverage of each point
      - Points should fall within dashed lines

**How to report on your model checks**

Generally speaking, model checks are pretty standard and not very exciting. Typically

> Usually we don't include these in a publication or final report. You could include them in Supplementary information. We just need to say and explain what checks were done and how you amended your data if neccessary to improve fit

## Make some adjustments to improve model fit

There are two ways we can improve the model fit for a linear model: 

- apply a transformation on the raw data
  - log, typically, log 10 `log10(var)` 
  - square root `sqrt(var)`
- if any, remove outliers 

Here we will focus on applying a `log10` transformation to the two relevant variables `leaf_mass_per_area` and `rainfall`. We will be creating a new variable using `mutate()` and will be assigning these new changes to `data_towers` into a new data object called `data_towers_transformed`.

```{r}
data_towers_transformed <- # Assign changes into a new dataset
  data_towers |> # start with data_towers
  mutate(
    # Create a new log10 transformed leaf mass per area
    log10_leaf_mass_per_area = log10(leaf_mass_per_area),
    # Create a new log10 transformed rainfall
    log10_rainfall = log10(rainfall)
  )

data_towers_transformed
```

## Fit model again

Let's try fit out model again using our transformed variables.

```{r}
towers_transformed_fit <- lm(log10_leaf_mass_per_area ~ log10_rainfall, data = data_towers_transformed)
```

## Check model assumptions again

Use `check_model()` on our new model fit using transformed data. How does it look?! 

```{r}
check_model(towers_transformed_fit)
```

By now it should be clear which is the better model fit.

## Let's compare the two models fitted to data

We will plot the data and the fitted models for both the original and transformed data. One of these models will be a better fit than the other. Hopefully you see why we transformed the data!

**Plot of original data**

```{r}
# Estimate means and confidence intervals
means_towers <- estimate_means(towers_og_fit, by = "rainfall")

# make the plot
ggplot(data_towers, aes(x = rainfall, y = leaf_mass_per_area)) +
  geom_point(size = 2, col = "red", alpha = 0.2, stroke = 0) +
  geom_ribbon(data = means_towers, aes(ymin = CI_low, ymax = CI_high, y = Mean), fill = "grey") +
  geom_line(data = means_towers, aes(y = Mean), col = "#EB8240", linewidth = 1) +
  theme_classic() +
  labs(
    title = "Response of woody-plants to rainfall",
    x = "Rainfall",
    y = "Leaf Mass per Area"
  )
```

Here we can see the issues identified by the mdoel checks in the plot:

- **Linearity**: The line goes outside the data, and even predicts a negative value at high rainfall. 
- **Homogeneity of variance**: The residuals do not have constant variance.  Data are much mroe spread towards the left of the plot than the right.
- **Normality of residuals**: The residuals are not normally distributed. They are skewed to have much larger deparures above compared to below the line.
- **Influential observations**: There are some points with really high y valkues that are likely having a disproportinate effect on the line


## Plot of transformed data

Here's a plot of the fitted model using the transformed data. Wow, what a difference! You can see the difference in the fit. The irmpoved fit of the model and meeting of asusmptions mean we can more condiently make interpretations on the relationship between rainfall and leaf mass per area based aropund the fitted model.

```{r}
# Estimate means and confidence intervals
means_towers_transformed <- estimate_means(towers_transformed_fit, by = "log10_rainfall")

# make the plot
ggplot(data_towers_transformed, aes(x = log10_rainfall, y = log10_leaf_mass_per_area)) +
  geom_point(size = 2, col = "red", alpha = 0.2, stroke = 0) +
  geom_ribbon(data = means_towers_transformed, aes(ymin = CI_low, ymax = CI_high, y = Mean), fill = "grey") +
  geom_line(data = means_towers_transformed, aes(y = Mean), col = "#EB8240", linewidth = 1) +
  theme_classic() +
  labs(
    title = "Response of woody-plants to rainfall",
    x = "log10 Rainfall",
    y = "log10 Leaf Mass per Area"
  )
```


## Over to you

For the remainder of the practical, we will get you to: 

- load a dataset
- fit a linear model
- check their assumptions
- make changes to the data to improve the model fit and adherance to assumptions
- make some interpretations on the results of the model

We have not provided the step-by-step instructions / R code for you to complete these exercises. Use the knowledge you've gained so far and apply them here. Make use of your saved code from the previous pracs and the worked example above if you need some guidance. 

> Check out the dplyr data transformation/manipulation cheatsheet [here](https://rstudio.github.io/cheatsheets/data-transformation.pdf)

![](images/data-transformation-cheatsheet-thumbs.png){60%}

