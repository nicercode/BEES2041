---
title: "Week 4-1 Linear model assumptions"
output: html_document
#   moodlequiz::moodlequiz:
#     replicates: 1
# moodlequiz:
#   category: "Week 4-1 Linear model assumptions"
# editor_options: 
#   chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

# remotes::install_github("numbats/moodlequiz")
library(moodlequiz)

library(tidyverse)
```

# Introduction to linear models

## Introduction

In the previous practical, we learned about using linear models to understand how `y` varies with a continuous `x` variable and a discrete `x` variable ...but how do we know our models are any good? Can we evaluate the validity of our linears models? 

In this practical, we will build on what we learned last week on fitting linear modeles. We will build on this knowledge and get you use to making interpretations. We will explore approaches in assessing our model fits and learn ways on how to improve our model fits using transformation. Throughout we will work with various real-world datasets. By the end of today, youâ€™ll have a solid foundation for applying these techniques to models you will be fitting in your own work.

## Key learning objectives

Our learning objective today are:

- **run** a **linear regression** in R using `lm()`
- **interpret** the output of a **linear regression** 
- **run diagnostic checks** on your  model output using `check_model()` to assess whether it meets the assumptions of a linear model.

<!-- using: -->
<!--   - `summary()` -->
<!--   - `parameters()` -->
<!--     - **extract** the **confidence interval** for the **slope** and **intercept** of the **regression** line -->
<!--   - `estimate_means()` -->
<!-- - **plot** the data and the **regression** line -->
<!--   - add the **confidence interval** using output of `estimate_means()` -->

Letâ€™s dive in! ðŸš€ 

![Image credit:  @allison_horst](images/r-learners.png){width=80%} <br>

## Setting up

**Materials:**

Everything you need for this prac is on Moodle

1. Download this week's materials zip file from Moodle, from the course page
2. Unzip the file by: 
  - MacOS: Double clicking the zipfile 
  - Windows: Right click on the zip file and click "Extract All" 
3. Move the extracted folder into the folder where you store materials for `BEES2041/` 
4. **Click on the Rstudio project file, eg. `Wk-4-1-lm-assumptions.Rproj`** to open the RStudio project and you're in!!!

We will be working with various datasets collected. These are in the folder `data/`.

You will work in the relevant Quarto document for this prac. Within each Quarto docs there are several challenges for you to complete on your own devices in order to **answer the questions on Moodle**.

**Setting up: Packages:**

We will also be working with packages from the `tidyverse` and `easystats`, building on skills from previous pracs. You should have these already installed on your machines.

> **Note** that when running R in the browser we need to install the packages each time we start a new session or after you've checked your answer

In case you don't have them installed, here is code for you to do so:
```{r, eval=FALSE}
# Uncomment and run only the lines below only if you have not previously installed these.
# install.packages("tidyverse")
# install.packages("easystats")
```

> Remember to load the packages into R to use em! 

```{r, results='hide', warning=FALSE, message=FALSE}
library(tidyverse)
library(easystats)
```

# LM continuous (Leaves)

## Worked example - Isaac with leaves across climates

![Remember Dr. Isaac Towers?! Image credit: Data Dan](images/isaac-plant-ecosystems.png){width=60%} <br>
We will be working with an example from Dr. Isaac Towers - a postdoc in the School of Biological, Earth & Environmental Sciences. Specifically, Isaac wants to know: How does a leaf's mass per area change with rainfall? His research is published in New Phytologist, you can have a read of his original study [here](https://nph.onlinelibrary.wiley.com/doi/10.1111/nph.19478). We will be working with the data Isaac compiled for us.  Recall, last week we ran a linear model using `log10_leaf_mass_per_area`, `log10_rainfall`, let's try run the same linear model again but with the raw, untransformed data.

## Read in data from a URL link

```{r}
# The link the contains our data
url <- "https://raw.githubusercontent.com/nicercode/BEES2041/refs/heads/main/week%203/Wk3-1-Linear-models/data/towers-2024.csv" 

# Read in the data, drop columns where their names start with `log10`
data_towers <- read_csv(url) |> 
  select(-starts_with("log10"))
```

## Fit model

```{r}
towers_og_fit <- lm(leaf_mass_per_area ~ rainfall, data = data_towers)
```

## Check model assumptions

Recall from lectures this week that the assumptions of a linear model assumes:

1. **Linear** relationship between `x` and `y` 
2. **Residuals** are **normally** distributed
3. **Constant variance** of residuals (homogeneity of variance)
4. No major **outliers** / influential observations
5. **Independence** of points (sampling design)
6. Our **samples represent the population** of interest? (sampling design)

The last two assumptions has two do with the sampling design. You can only check the validity of these by carefully considering the how data was collection. The remaining assumptions we can check using the the outputs of `check_model()`.

> Note, you may need to click on "Zoom" to give the plots some room to breathe

```{r}
check_model(towers_og_fit)
```

In [this week's lectures](https://youtu.be/zzFyjTnAa8Y?si=LpkRecpF0LSVu91N), Data Data goes through how to use the four main plots neccessary for checking the assumptions of a liner model: 

1. **Linearity**
    - Check the relationship between fitted values and residuals
        - Should see no structure or patterns/curvature

2. **Normality of Residual**
    - Check the Quantile-Quantile plot
        - Sample points should fall along the line

3. **Homogeneity of Variance**
    - Check the relationship between fitted values and square root of standardised residuals
        - Line should be flat and horizontal
        - No clear pattern in points e.g. fanning out or grouping

4. **Influential Observations**
    - Check the leverage of each point
      - Points should fall within dashed lines

**How to report on your model checks**

Generally speaking, model checks are pretty standard and not very exciting. Typically

> Usually we don't include these in a publication or final report. Could include in eSupp. We just need to say and explain what checks were done and how you amended your data if neccessary to improve fit

## Make some adjustments to improve model fit

There are two ways we can improve the model fit for a linear model: 

- apply a transformation on the raw data
  - log, typically, log 10 `log10(var)` 
  - square root `sqrt(var)`
- if any, remove outliers 

Here we will focus on applying a `log10` transformation to two relevant variables `leaf_mass_per_area` and `rainfall`. We will be creating a new variable using `mutate()` and will be assigning these new changes to `data_towers` into a new data object called `data_towers_transformed`

```{r}
data_towers_transformed <- data_towers |>  # Assign changes in data_towers into a new dataset
  mutate(log10_leaf_mass_per_area =  log10(leaf_mass_per_area), # Create a new log10 transformed leaf mass per area
         log10_rainfall = log10(rainfall)) # Create a new log10 transformed rainfall
```

## Fit model again

Let's try fit out model again using our transformed variables
```{r}
towers_transformed_fit <- lm(log10_leaf_mass_per_area ~ log10_rainfall, data = data_towers_transformed)
```

## Check model assumptions again

Use `check_model()` on our new model fit using transformed data. How does it look?! 

```{r}
check_model(towers_transformed_fit)
```

# Over to you

For the remainder of the practical, we will get you to: 

- fit various linear models
- check their assumptions
- make changes to the data to improve the model fit and adherance to assumptions
- make some interpretations on the results of the model

We have not provided the step-by-step instructions / R code for you to complete these exercises. Use the knowledge you've gained so far and apply them here. Make use of your saved code from the previous pracs and the worked example above if you need some guidance. 

> Check out the dplyr data transformation/manipulation cheatsheet [here](https://rstudio.github.io/cheatsheets/data-transformation.pdf)

![](images/data-transformation-cheatsheet-thumbs.png){60%}

# Example 1: Boiling point of water vs. air pressure

![Ever notice that water boils quicker at high altitudes? Image credit: Slower Hiking](images/boiling-water-at-elevation.jpg){60%}

In the 1840's, the Scottish physicist Dr James Forbes travelled to the Swiss Alps and made many measurements of how the boiling point of water varied with air pressure (which decreases with altitude). In his research paper , Forbes also presented data collected on the measures of the same two quantities by Dr Joseph Hooker (famous botanist, explorer, friend of Charles Darwin). Unlike Forbes, however, Hooker took his measurements in the Himalayan Mountains, generally at higher altitudes.

The data we will explore here are a subset of Hooker's data containg 31 observations:
- `Temperature` at boiling point of water (degrees Fahrenheit)
- `Pressure`, the corrected barometric pressure (inches of mercury). 

> We want to know whether changes in pressure (which decreases with altitude) affects the boiling point of water. 

Start by reading the data  `data/Hooker.csv` into R.
**Exercise:**

Use R to:
- plot a graph of Temperature versus Pressure with `ggplot2`
  - consider labelling your points with the row number of each value
- conduct the linear regression analysis using `lm()` (Temperature = a + b*Pressure)
- evaluate whether your model fit is in line with the assumptions of a linear model using `check_model()`

```{r}
library(tidyverse)
library(easystats)

# Read in data
data_hooker <- read_csv("week 4/Wk4-1-moodle/data/Hooker.csv")

# Plot raw data
data_hooker |> 
  mutate(obs_id = row_number()) |>  # Create a temporary variable that denotes the row number of each observation
ggplot(aes(x = Pressure, y = Temperature)) + 
  geom_text(aes(label = obs_id)) # A scatterplot where each point is the observation number
  theme_classic()

# Fit the model with all data
hooker_fit <- lm(Temperature ~ Pressure, data = data_hooker)

# Check model
check_model(hooker_fit)

# Exclude potential outlier
data_hooker_norow7 <- data_hooker |> 
   slice(-7)

# Fit the model with all data
hooker_norow7_fit <- lm(Temperature ~ Pressure, data = data_hooker_norow7)

# Check model
check_model(hooker_norow7_fit) # Not really improve things..

# Transform data instead
data_hooker_transformed <- data_hooker |> 
  mutate(log10_temp = log10(Temperature),
         log10_pressure = log10(Pressure))

# Fit the model with all data
hooker_transformed_fit <- lm(log10_temp ~ log10_pressure, data = data_hooker_transformed)

# Check model
check_model(hooker_transformed_fit) # There is an improvement but probably good to remove outlier

# Remove outlier in transformed data
data_hooker_transformed_norow7  <- data_hooker_transformed |> 
   slice(-7)

# Fit the model with all data
hooker_transformed_norow7_fit <- lm(log10_temp ~ log10_pressure, data = data_hooker_transformed_norow7)

# Check model
check_model(hooker_transformed_norow7_fit) # Heaps better!
```

**Questions**
1. Is there evidence of violating assumptions, through outliers, non-linearity or non-constant error variance?

2. You notice that point 7 looks a bit out of place an.After some investigation, it turns out there were machinery issues when the data was recorded. You decide that's sufficient reason to exclude the point as an outlier. 

In `dplyr`, the function `slice` gives us a subset of rows by row number. Placing a minus `-` sign in front of that number will give us all rows **except** that one listed. To remove row 7, we would use:

```{r}
data_hooker_norow7 <-  data_hooker |> slice(-7)
```

Did removing the outliers improve any problems with this dataset?

Rerun your linear model with your new dataset and check your model again

3. Removing the outlier didn't really help... let's try transforming the data. `log10` transform your x and y variable and rerun the linear model analysis and model checks

Recall to use `mutate()` to create a new variable containing your transformed data.

- Write down the fitted equation: log10(Temp) = XX + XX * log10(Pressure)
- What is the F-value
- What is the P-value

4. What data adjustments would you recommend for a linear model for the Hooker dataset? 

# Example 2: Growth rates vs. individual size



# Example 3: Brain weight vs. body size
# Example 4: Body size vs fecundity
# Example 5: River flow and density of larval fish
# Example 6: Koalas and fire regimes


